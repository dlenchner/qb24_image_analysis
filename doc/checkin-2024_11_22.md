

# Check-in Number 2 - November 22, 2024 #

## Addressing prior feedback ##

- The biggest point of criticism brought up after our last check-in and during the peer review stage was related to the names of our script files. Admittedly, they were not very descriptive at all and needed to be renamed. As such, we have renamed them and reorganized the earlier test scripts to make the function of each script clearer.

- In response to some of the suggestions offered to our questions and struggles from the last check-in, we have optimized our code (at least relative to how it functioned before) to effectively analyze fluorescent intensity in regions of interest in an image, report that fluorescent data in a report file, and generate a metadata file that contains important information about each image.

- As a quality control, we have implemented an if statement that only converts images to grayscale if its necessary (meaning, if they are not already in grayscale).


## Project progress ##

We have finalized two python scripts:
- single_image_analysis.py
  - When run as a program in the Terminal command line, this script will:
    - Read in an image file (hard-coded into the script)
    - Convert the image to grayscale, if necessary
    - Apply a Gaussian blur to the image
    - Threshold the image automatically
    - Establish a binary mask based on the threshold value
    - Identify indiviaul objects in the image that have signal intensities above the threshold value
    - Filter out any small objects that may not be real regions of interest
    - Calculate the size of each region, the total fluorescent intensity of each region, and the average intensity per pixel of each region
    - Report the image metadata in an image_metadata.tsv file and the intensity data in an image_data.tsv file
- multi_image_analysis.py
  - When run as a program in the Terminal command line, this script will:
    - Perform the same functions as the single_image_analysis.py script, but apply it to every image located in the data directory of this repository (the images are not hard-coded into the script, but the path to the directory is)
    - Generate a report file and metadata file where the data taken from every image is concatenated


Looking at our proposed steps, we have completed steps 1 and 2 (and improved upon the code that satisfied these steps from our last check-in), as well as step 3. As a side note, some of the specifics that we envisioned at the start of this project have been altered as we've learned more and worked to the point we're at now. For instance, we haven't subtracted background intensity from regions of interest, but we have thresholded automatically and identified and analyzed regions that are above the threshold.

1. ~~Read an individual image file into Python, quantify fluorescence intensity at each pixel, and report that fluorescence intensity.~~
2. ~~Build on the work in step 1 by developing code that can isolate a region of interest, subtract background intensity, and report the average fluorescence intensity just in that region.~~
3. ~~Modify the code to analyze two or more images at a time.~~
4. Read the fluorescence intensity data from each image into R.
5. Generate a plot in R that displays the fluorescence intensity data from each of the images.


## Project organization ##

    ├── README.md
    ├── data
    │   ├── 962_F1_1_blue.png
    │   ├── A1_c2.jpg
    │   ├── FluorescentCells.jpg
    │   └── GMC101_miR71KO-40x_DAPI.jpg
    ├── doc
    │   ├── checkin-2024_11_01.md
    │   └── checkin-2024_11_22.md
    ├── requirements.txt
    ├── results
    │   ├── image_1_962_F1_1_blue.png_annotated.png
    │   ├── image_2_A1_c2.jpg_annotated.png
    │   ├── image_3_FluorescentCells.jpg_annotated.png
    │   ├── image_4_GMC101_miR71KO-40x_DAPI.jpg_annotated.png
    │   ├── image_data.tsv
    │   └── image_metadata.tsv
    └── src
        ├── initial_test_code
        │   ├── test1_pixel_intensity_single_image.py
        │   ├── test2_alt_avg_intensity_single_image.py
        │   ├── test2_avg_intensity_single_image.py
        │   └── test3_thresholding_masking_single_image.ipynb
        ├── multi_image_analysis.py
        └── single_image_analysis.py


## Struggles and obstacles ##

Software
- We've updated our requirements.txt file to provide information on what packages are required in python to run our scripts
- However, we aren't certain that this information is particularly helpful, given that those packages are readily identifiable in the scripts themselves
- We struggled to create a conda environment (and, frankly, aren't entirely sure what it means to set up a conda environment) and environment.yml file that worked

Datasets
- We still haven't been able to find a set of images that are easy to access and that will showcase our code well
- We will keep exploring the [Image Data Resource](http://idr.openmicroscopy.org) 

Next steps
- We are struggling to figure out how to display the data we get from each image in R (this was a stretch goal at the beginning of the project, and we're still not certain we'll get through it before it's time to present our project next week)


## Questions ##

- How should we report required softwares and packages?
- How would you suggest displaying the average intensity data per pixel in each region using ggplot in R? What plot type? What parameters?
- If we identify a good set of images, but they are too large to share (git push) to our repository, how can we report them in our repository?
- Is it a good idea to add in a file that walks the viewer through running our code?